{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pymupdf\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..'\n",
    "data_folder = 'data'\n",
    "script_folder = 'scripts'\n",
    "config_file = 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pjoin(root, config_file), 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_superheroes = config['LIST_OF_SUPERHEROES']\n",
    "superhero_synonyms = config['SUPERHERO_SYNONYMS']\n",
    "movies_list_of_superheroes = config['MOVIES_LIST_OF_SUPERHEROES']\n",
    "\n",
    "dialogue_folder = 'dialogues'\n",
    "max_context_length = 100\n",
    "dialogues_joiner = '\\n|_/-|_/-|_/-|_/-|_/-|_/-|_/-|_/-|_/-|_/-|\\n\\n'\n",
    "data_folder_path = pjoin(root, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movie_scripts = os.listdir(pjoin(root, data_folder, script_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf = pymupdf.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in pdf:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def get_all_superhero_names(superhero, superhero_synonyms):\n",
    "    superhero_synonym = superhero_synonyms[superhero][0]\n",
    "    superhero_names = [superhero.upper(), superhero_synonym.upper(), superhero_synonym.replace(' ', '-').upper()]\n",
    "    superhero_names = superhero_names + [i.upper () for i in superhero_synonym.split()]\n",
    "    return superhero_names\n",
    "\n",
    "def split_script_by_superhero_dialogue(script_text, superhero_names):\n",
    "    matches = re.finditer(\"|\".join(superhero_names), script_text)\n",
    "    split_points = [match.start() for match in matches][1:] + [len(script_text)]\n",
    "    extrcated_split_script_text = [script_text[split_points[i]:split_points[i+1]] for i in range(len(split_points) - 1)]\n",
    "    return extrcated_split_script_text\n",
    "\n",
    "def remove_extra_charachters_dialogue_from_each_split(extrcated_split_script_text, max_extra_dialogues=3):\n",
    "    pattern = re.compile(r'^[A-Z\\s\\'().,-]+$', re.MULTILINE)\n",
    "    extrcated_split_script_text_filtered = []\n",
    "\n",
    "    for idx in range(len(extrcated_split_script_text)):\n",
    "        matches = re.finditer(pattern, extrcated_split_script_text[idx])\n",
    "        indices = [match.start() for match in matches]\n",
    "        if len(indices) >=1:\n",
    "            max_indices = len(extrcated_split_script_text[idx]) if len(indices) == 1 else indices[:max_extra_dialogues][-1]\n",
    "            extrcated_split_script_text_filtered.append(extrcated_split_script_text[idx][:max_indices])\n",
    "    \n",
    "    return extrcated_split_script_text_filtered\n",
    "\n",
    "def combine_dialogue_with_context(script_text, extrcated_split_script_text_filtered, max_context_length):\n",
    "    \n",
    "    dialogue_with_context_all = []\n",
    "    for idx in range(len(extrcated_split_script_text_filtered)):\n",
    "        dialogue_idx = script_text.find(extrcated_split_script_text_filtered[idx])\n",
    "        dialogue_with_context = script_text[dialogue_idx-max_context_length:dialogue_idx] + extrcated_split_script_text_filtered[idx]\n",
    "        dialogue_with_context_all.append(dialogue_with_context)\n",
    "\n",
    "    return dialogue_with_context_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01d346da1264917b73cb5abea73c357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for superhero in tqdm(list_of_superheroes):\n",
    "    superhero_script = []\n",
    "    for script in movies_list_of_superheroes[superhero]:\n",
    "        superhero_dialogue_save_path = pjoin(data_folder_path, dialogue_folder, superhero)\n",
    "        save_script_name = \".\".join(script.split('.')[:-1])+'.txt'\n",
    "        script_path = pjoin(data_folder_path, script_folder, script)\n",
    "        os.makedirs(superhero_dialogue_save_path, exist_ok=True)\n",
    "\n",
    "        script_text = extract_text_from_pdf(script_path)\n",
    "        superhero_names = get_all_superhero_names(superhero, superhero_synonyms)\n",
    "        extrcated_split_script_text = split_script_by_superhero_dialogue(script_text, superhero_names)\n",
    "        extrcated_split_script_text_filtered = remove_extra_charachters_dialogue_from_each_split(extrcated_split_script_text, max_extra_dialogues=3)\n",
    "        dialogues_with_context = combine_dialogue_with_context(script_text, extrcated_split_script_text_filtered, max_context_length)\n",
    "        dialogues_with_context_combined = f\"{dialogues_joiner}\".join(dialogues_with_context)\n",
    "        with open(pjoin(superhero_dialogue_save_path, save_script_name), 'w') as f:\n",
    "            f.write(dialogues_with_context_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import transformers\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "\n",
    "# def load_model_pipeline(model_id, batch_size):\n",
    "#     pipeline = transformers.pipeline(\n",
    "#         \"text-generation\",\n",
    "#         model=model_id,\n",
    "#         model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#         device_map=\"auto\",\n",
    "#         batch_size=batch_size,\n",
    "#     )\n",
    "\n",
    "#     torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "#     torch.backends.cuda.enable_flash_sdp(False)\n",
    "#     return pipeline\n",
    "\n",
    "# def extract_dialogue_from_llm(pipeline, messages):\n",
    "\n",
    "#     pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "#     pipeline.tokenizer.padding_side = 'left'\n",
    "\n",
    "#     terminators = [\n",
    "#         pipeline.tokenizer.eos_token_id,\n",
    "#         pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "#     ]\n",
    "\n",
    "#     outputs = pipeline(\n",
    "#         messages,\n",
    "#         max_new_tokens=256,\n",
    "#         eos_token_id=terminators,\n",
    "#         do_sample=True,\n",
    "#         temperature=1,\n",
    "#         top_p=1,\n",
    "#     )\n",
    "\n",
    "#     return outputs\n",
    "\n",
    "# def create_batch(extrcated_split_script_text, superhero, superhero_names, batch_size):\n",
    "    \n",
    "#     messages_batch = []\n",
    "#     for extracted_text in tqdm(extrcated_split_script_text[:batch_size]):\n",
    "#         system_prompt = f\"You are a movie dialogue separator. From the context you are given, separate the dialogue and provide the dialogue of a charachter. You are only allowed to give final dialoige without any thing. Don't say anything else, just list the dialogue. Always start with the NAME of the character followed by a colon and then the dialogue. The extracted dialogue should always be in single line. Make sure that you extract all the dialouges of the asked charachters. It can be present in multiple lines. These are the identifier for charachter dialoges for which you need to extrcat the dialouges: {\", \".join([f\"'{i}'\" for i in superhero_names])} The identifier are always in captital leter.\"\n",
    "#         user_prompt = f\"Extract only the dialogues of {superhero.upper()} - Synonyms of {superhero.upper()} are {\", \".join([f\"'{i}'\" for i in superhero_names])}. Now extract dialogue based on the synonyms given from the following text\\n\\n\\n\\n {extracted_text} \\n\\n\\n\\n\\n Make sure you only extract dialogue of {\", \".join([f\"'{i}'\" for i in superhero_names])}. The dialogues starts only after the name of the charachter is in capital letter.\"\n",
    "\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": system_prompt},\n",
    "#             {\"role\": \"user\", \"content\": user_prompt},\n",
    "#         ]\n",
    "#         messages_batch.append(messages)\n",
    "#     return messages_batch\n",
    "\n",
    "# batch_size = 8\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# pipeline = load_model_pipeline(model_id, batch_size)\n",
    "# messages_batch = create_batch(extrcated_split_script_text, superhero, superhero_names, batch_size)\n",
    "# extrcated_dialogue = extract_dialogue_from_llm(pipeline, messages_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
