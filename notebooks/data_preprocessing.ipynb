{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import pymupdf\n",
    "import transformers\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef726b83a3154c129cf2ef9836cf99ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..'\n",
    "data_folder = 'data'\n",
    "script_folder = 'scripts'\n",
    "config_file = 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pjoin(root, data_folder, config_file), 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movie_scripts = os.listdir(pjoin(root, data_folder, script_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf = pymupdf.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in pdf:\n",
    "        text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_superheroes = config['LIST_OF_SUPERHEROES']\n",
    "superhero_synonyms = config['SUPERHERO_SYNONYMS']\n",
    "movies_list_of_superheroes = config['MOVIES_LIST_OF_SUPERHEROES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for superhero in list_of_superheroes:\n",
    "    superhero_script = []\n",
    "    for script in movies_list_of_superheroes[superhero]:\n",
    "        script_path = pjoin(root, data_folder, script_folder, script)\n",
    "        script_text = extract_text_from_pdf(script_path)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "superhero_synonym = superhero_synonyms[superhero][0]\n",
    "superhero_names = [superhero.upper(), superhero_synonym.upper(), superhero_synonym.replace(' ', '-').upper()]\n",
    "superhero_names = superhero_names + [i.upper () for i in superhero_synonym.split()]\n",
    "\n",
    "matches = re.finditer(\"|\".join(superhero_names), script_text)\n",
    "split_points = [match.start() for match in matches][1:] + [len(script_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrcated_split_script_text = [script_text[split_points[i]:split_points[i+1]] for i in range(len(split_points) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dialogue_from_llm(superhero, superhero_names, extracted_text):\n",
    "    system_prompt = f\"You are a movie dialogue separator. From the context you are given, separate the dialogue and provide the dialogue of a charachter. You are only allowed to give final dialoige without any thing. Don't say anything else, just list the dialogue. Always start with the NAME of the character followed by a colon and then the dialogue. The extracted dialogue should always be in single line. Make sure that you extract all the dialouges of the asked charachters. It can be present in multiple lines. These are the identifier for charachter dialoges for which you need to extrcat the dialouges: {\", \".join([f\"'{i}'\" for i in superhero_names])} The identifier are always in captital leter.\"\n",
    "    user_prompt = f\"Extract only the dialogues of {superhero.upper()} - Synonyms of {superhero.upper()} are {\", \".join([f\"'{i}'\" for i in superhero_names])}. Now extract dialogue based on the synonyms given from the following text\\n\\n\\n\\n {extracted_text} \\n\\n\\n\\n\\n Make sure you only extract dialogue of {\", \".join([f\"'{i}'\" for i in superhero_names])}. The dialogues starts only after the name of the charachter is in capital letter.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "    )\n",
    "\n",
    "    extracted_dialogue = outputs[0][\"generated_text\"][-1]['content'].replace('\\n', ' ')\n",
    "    return extracted_dialogue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrcated_dialogue_full = []\n",
    "\n",
    "for extracted_text in tqdm(extrcated_split_script_text):\n",
    "    extrcated_dialogue = extract_dialogue_from_llm(superhero, superhero_names, extracted_text)\n",
    "    extrcated_dialogue_full.append(extrcated_dialogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    terminators = [\n",
    "        pipeline.tokenizer.eos_token_id,\n",
    "        pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25130cfe171d4227a011dc1fc5ae108d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = []\n",
    "for extracted_text in tqdm(extrcated_split_script_text[:4]):\n",
    "    system_prompt = f\"You are a movie dialogue separator. From the context you are given, separate the dialogue and provide the dialogue of a charachter. You are only allowed to give final dialoige without any thing. Don't say anything else, just list the dialogue. Always start with the NAME of the character followed by a colon and then the dialogue. The extracted dialogue should always be in single line. Make sure that you extract all the dialouges of the asked charachters. It can be present in multiple lines. These are the identifier for charachter dialoges for which you need to extrcat the dialouges: {\", \".join([f\"'{i}'\" for i in superhero_names])} The identifier are always in captital leter.\"\n",
    "    user_prompt = f\"Extract only the dialogues of {superhero.upper()} - Synonyms of {superhero.upper()} are {\", \".join([f\"'{i}'\" for i in superhero_names])}. Now extract dialogue based on the synonyms given from the following text\\n\\n\\n\\n {extracted_text} \\n\\n\\n\\n\\n Make sure you only extract dialogue of {\", \".join([f\"'{i}'\" for i in superhero_names])}. The dialogues starts only after the name of the charachter is in capital letter.\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    m.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128009 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "    outputs = pipeline(\n",
    "        m,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here is the extracted dialogue of the corresponding characters:  BATMAN: 5 children. 6...  That's enough! He goes back in cuffs. Not a coffin.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][0][\"generated_text\"][-1]['content'].replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'^[A-Z\\s\\'().,-]+$', re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.finditer(pattern, extrcated_split_script_text[1])\n",
    "indices = [match.start() for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_indices = indices[0] if len(indices) == 1 else indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATMAN(CON'T)\n",
      "(angry)\n",
      "4 women.\n",
      "He PUNCHES Zsasz in the STOMACH sending him to his knees,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extrcated_split_script_text[1][:max_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATMAN(CON'T)\n",
      "(angrier)\n",
      "5 children.\n",
      "He CRACKS him across the JAW.\n",
      "Zsasz LAUGHS and SMILES through CRACKED, BLOODSTAINED TEETH.\n",
      "ZSASZ\n",
      "6... \n",
      "(coughs)\n",
      "6 children.\n",
      "Batman's eyes fill with HATE.\n",
      "He SNATCHES Zsasz's WINDPIPE and begins to SQUEEZE.\n",
      "In a FRENZY he starts to RAIN DOWN BLOWS.\n",
      "ONE -- TWO -- THREE--\n",
      "His arm is GRABBED and YANKED back.\n",
      "MAN(O.S)\n",
      "(firmly)\n",
      "That's enough!\n",
      "Batman SPINS around and finds himself FACE to FACE with a\n",
      "MAN, mid 20's, MASKED and DRESSED in BLACK with A DARK BLUE\n",
      "BIRD SYMBOL on his CHEST. This is DICK GRAYSON, FORMER\n",
      "ROBIN, now NIGHTWING.\n",
      "NIGHTWING(CON'T)\n",
      "(serious)\n",
      "He goes back in cuffs. Not a\n",
      "coffin.\n",
      "8FLiX.com SCREENPLAY DATABASE \n",
      "FOR EDUCATIONAL USE ONLY\n",
      "28.\n",
      "Batman UNCLENCHES his FIST and looks down on Zsasz's BLOODY\n",
      "and SWOLLEN face.\n",
      "Batman DROPS him.\n",
      "The Serial Killer still emits SOFT LAUGHTER through his\n",
      "BUSTED mouth.\n",
      "SIRENS can be heard.\n",
      "Batman PULLS his arm free of Nightwing's GRIP and marches\n",
      "toward the Batmobile.\n",
      "Nightwing watches him leave and DEPARTS before the G.C.P.D\n",
      "arrive on the scene.\n",
      "EXT. ROOFTOP, TALL BUILDING, GOTHAM -- LATER\n",
      "Batman stands on the rooftop looking out into Gotham.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(extrcated_split_script_text[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2==2.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "PyPDF2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Open the PDF file\n",
    "file_path = \"/home/quamer23nasim38/Superhero-Character-Based-On-RAG-AI-Using-Haystack-And-Qdrant/data/spider-man-no-way-home-2021.pdf\"\n",
    "pdf_file = open(file_path, \"rb\")\n",
    "\n",
    "# Create a PDF reader object\n",
    "pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "\n",
    "# Get the total number of pages\n",
    "total_pages = pdf_reader.numPages\n",
    "\n",
    "# Function to extract text from each page and filter Spider-Man's dialogues\n",
    "def extract_spiderman_dialogues(reader, total_pages):\n",
    "    dialogues = []\n",
    "    spider_man_lines = False\n",
    "    for page_num in range(total_pages):\n",
    "        page = reader.getPage(page_num)\n",
    "        text = page.extract_text()\n",
    "        lines = text.split(\"\\n\")\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.strip() == \"SPIDER-MAN\":\n",
    "                spider_man_lines = True\n",
    "                dialogues.append(line.strip())\n",
    "            elif spider_man_lines and line.strip() and not line.startswith(\" \"):\n",
    "                dialogues.append(line.strip())\n",
    "            elif not line.strip():\n",
    "                spider_man_lines = False\n",
    "    \n",
    "    return dialogues\n",
    "\n",
    "# Extract Spider-Man's dialogues\n",
    "spiderman_dialogues = extract_spiderman_dialogues(pdf_reader, total_pages)\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()\n",
    "\n",
    "spiderman_dialogues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiderman_dialogues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
