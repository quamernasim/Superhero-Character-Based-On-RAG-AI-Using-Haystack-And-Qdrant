{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This whole blog is divided into 4 parts. Let's see what we are going to do in each part and understand the WHYs behind it.\n",
    "- Part 1: Data Collection and Data Preprocessing - Here we will collect the movie scripts from the internet. We will then preprocess the data to make it ready for ingestion.\n",
    "- Part 2: Data Ingestion and Data Indexing - Here we will ingest and index the data into the Qdrant Vector Database using FastEmbed.\n",
    "- Part 3: RAG-Based chatbot for mimicking the conversation - We finally use the indexed data to build a character chatbot using the Haystack framework.\n",
    "- Part 4: Building a User Interface for the chatbot - Finally, we will build a user interface for the chatbot using Streamlit.\n",
    "\n",
    "Now, let's start with each part one by one and look into the implementational details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move any further, let's first see all the list of superheroes whose dialogues we are going to use to build the Character Chatbot. I have also noted down the real names of the superheroes to extract the dialogues from the movie scripts. Apart from this, I have also noted down the movie names for each superhero that we have in our list. All these details are saved in a .yaml file. Let's see the contents of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen all the superheroes whose dialogues we are going to use, let's move to the next part where we will do the data preprocessing to extract the dialogues along with it's small context from the movie scripts. We not only need the dialogues but also the context in which the dialogues are spoken. This will help us in building a better chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first define some constants like location of the data files, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..'\n",
    "data_folder = 'data' # folder where all the data is stored\n",
    "script_folder = 'scripts' # folder where all the scripts are stored\n",
    "config_file = 'config.yaml' # file where the configuration is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now let's load the configuration file so that we can use the details of the superheroes in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "# used to load the pdfs\n",
    "import pymupdf\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# load the configuration\n",
    "with open(pjoin(root, config_file), 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# used to loop through the scripts\n",
    "list_of_superheroes = config['LIST_OF_SUPERHEROES']\n",
    "\n",
    "# very essential for efficient dialogue extraction\n",
    "# in some scripts, the name of the superhero name are interchanged with their real names\n",
    "superhero_synonyms = config['SUPERHERO_SYNONYMS']\n",
    "\n",
    "# used to get the relevant scripts for a particular superhero\n",
    "movies_list_of_superheroes = config['MOVIES_LIST_OF_SUPERHEROES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to save the dialogues that are extracted from the scripts\n",
    "dialogue_folder = 'dialogues'\n",
    "# with each dialogue, we want to have a context of the previous dialogues so that the model can learn and understand the dialogues better\n",
    "# we will try to keep the context length small\n",
    "max_context_length = 100\n",
    "# each dialogue will be combined with the previous dialogues and in between them, we will add a special token\n",
    "# this is done so as to have one single txt file for a movie for a particular superhero\n",
    "dialogues_joiner = '\\n|_/-|_/-|_/-|_/-|_/-|_/-|_/-|_/-|_/-|_/-|\\n\\n'\n",
    "\n",
    "# used to load the pdfs of the scripts\n",
    "data_folder_path = pjoin(root, data_folder)\n",
    "all_movie_scripts = os.listdir(pjoin(root, data_folder, script_folder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have defined some additional constants like the folder where we will save the dialogues, the maximum context length that we want to keep associated with each extracted dialogue, and the special token that we will use to join the dialogues so that we can have one single txt file for each dialogue of a movie for a particular superhero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = pjoin(root, data_folder)\n",
    "all_movie_scripts = os.listdir(pjoin(root, data_folder, script_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    '''\n",
    "    This function extracts the text from a pdf file using the pymupdf library\n",
    "    '''\n",
    "    # open the pdf file\n",
    "    pdf = pymupdf.open(pdf_path)\n",
    "    text = ''\n",
    "    for page in pdf:\n",
    "        # extract the text from the page and keep adding it to the text variable\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "def get_all_superhero_names(superhero, superhero_synonyms):\n",
    "    '''\n",
    "    With each superhero, we will have a list of names that the superhero can be referred to in the script\n",
    "    For example, for Batman, the names can be Batman, Bruce Wayne, Bruce, Wayne, Bruce-Wayne, etc.\n",
    "    '''\n",
    "\n",
    "    # get the superhero synonym which essentially is the real name of the superhero\n",
    "    superhero_synonym = superhero_synonyms[superhero][0]\n",
    "    # get all the possible names of the superhero\n",
    "    superhero_names = [superhero.upper(), superhero_synonym.upper(), superhero_synonym.replace(' ', '-').upper()]\n",
    "    superhero_names = superhero_names + [i.upper () for i in superhero_synonym.split()]\n",
    "    return superhero_names\n",
    "\n",
    "def split_script_by_superhero_dialogue(script_text, superhero_names):\n",
    "    '''\n",
    "    This function splits the script such that we have the split points where the dialogues of the superhero start\n",
    "    Since we're only interested in the dialogues of the superhero, we will split the script based on the dialogues of the superhero\n",
    "    '''\n",
    "    # we will find all the matches of the superhero names in the script\n",
    "    matches = re.finditer(\"|\".join(superhero_names), script_text)\n",
    "    # get the split points where the dialogues of the superhero start\n",
    "    split_points = [match.start() for match in matches][1:] + [len(script_text)]\n",
    "    # extract the dialogues of the superhero\n",
    "    extrcated_split_script_text = [script_text[split_points[i]:split_points[i+1]] for i in range(len(split_points) - 1)]\n",
    "    return extrcated_split_script_text\n",
    "\n",
    "def remove_extra_charachters_dialogue_from_each_split(extrcated_split_script_text, max_extra_dialogues=3):\n",
    "    '''\n",
    "    This function removes the extra characters from the dialogues extracted from the script\n",
    "    It checks if there are other characters in the dialogues other than the dialogues of the superhero\n",
    "    This is done by checking if a line has only uppercase characters, spaces, and some special characters\n",
    "    This means that the line is indicative of a start of a new dialogue\n",
    "    We only keep the dialogues till the max_extra_dialogues and remove the rest\n",
    "    '''\n",
    "    # pattern to check if a line has only uppercase characters, spaces, and some special characters\n",
    "    pattern = re.compile(r'^[A-Z\\s\\'().,-]+$', re.MULTILINE)\n",
    "    extrcated_split_script_text_filtered = []\n",
    "\n",
    "    for idx in range(len(extrcated_split_script_text)):\n",
    "        # find all the matches of the pattern in the dialogue\n",
    "        matches = re.finditer(pattern, extrcated_split_script_text[idx])\n",
    "        # get the indices of the matches\n",
    "        indices = [match.start() for match in matches]\n",
    "        # if there are more than max_extra_dialogues, we only keep the dialogues till the max_extra_dialogues\n",
    "        if len(indices) >=1:\n",
    "            max_indices = len(extrcated_split_script_text[idx]) if len(indices) == 1 else indices[:max_extra_dialogues][-1]\n",
    "            extrcated_split_script_text_filtered.append(extrcated_split_script_text[idx][:max_indices])\n",
    "    \n",
    "    return extrcated_split_script_text_filtered\n",
    "\n",
    "def combine_dialogue_with_context(script_text, extrcated_split_script_text_filtered, max_context_length):\n",
    "    '''\n",
    "    Combine the dialogues with the context of the previous dialogues.\n",
    "    This is very essential for the model to learn the dialogues better. A dialogue without context is of no use.\n",
    "    Dialogues when combined with the context of the previous dialogues can help the model understand the dialogues better.\n",
    "    '''\n",
    "    dialogue_with_context_all = []\n",
    "    # loop through all the dialogues\n",
    "    for idx in range(len(extrcated_split_script_text_filtered)):\n",
    "        # for each dialogue, get the index of the start of the dialogue in the script\n",
    "        dialogue_idx = script_text.find(extrcated_split_script_text_filtered[idx])\n",
    "        # add the context of the previous dialogues to the current dialogue and append it to the list\n",
    "        dialogue_with_context = script_text[dialogue_idx-max_context_length:dialogue_idx] + extrcated_split_script_text_filtered[idx]\n",
    "        dialogue_with_context_all.append(dialogue_with_context)\n",
    "\n",
    "    return dialogue_with_context_all\n",
    "\n",
    "# loop through all the superheroes\n",
    "for superhero in tqdm(list_of_superheroes):\n",
    "    superhero_script = []\n",
    "    # loop through all the scripts of the superhero\n",
    "    for script in movies_list_of_superheroes[superhero]:\n",
    "        superhero_dialogue_save_path = pjoin(data_folder_path, dialogue_folder, superhero)\n",
    "        save_script_name = \".\".join(script.split('.')[:-1])+'.txt'\n",
    "        script_path = pjoin(data_folder_path, script_folder, script)\n",
    "        os.makedirs(superhero_dialogue_save_path, exist_ok=True)\n",
    "\n",
    "        # extract the text from the pdf\n",
    "        script_text = extract_text_from_pdf(script_path)\n",
    "        # get all the names of the superhero\n",
    "        superhero_names = get_all_superhero_names(superhero, superhero_synonyms)\n",
    "        # split the script based on the dialogues of the superhero\n",
    "        extrcated_split_script_text = split_script_by_superhero_dialogue(script_text, superhero_names)\n",
    "        # remove the extra characters from the dialogues\n",
    "        extrcated_split_script_text_filtered = remove_extra_charachters_dialogue_from_each_split(extrcated_split_script_text, max_extra_dialogues=3)\n",
    "        # combine the dialogues with the context of the previous dialogues\n",
    "        dialogues_with_context = combine_dialogue_with_context(script_text, extrcated_split_script_text_filtered, max_context_length)\n",
    "        # join the dialogues with the context\n",
    "        dialogues_with_context_combined = f\"{dialogues_joiner}\".join(dialogues_with_context)\n",
    "        # save the dialogues with the context to a txt file\n",
    "        with open(pjoin(superhero_dialogue_save_path, save_script_name), 'w') as f:\n",
    "            f.write(dialogues_with_context_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code that does the following:\n",
    "- Extracts the text from the pdf file using the PyMuPDF library.\n",
    "- Splits the script based on the dialogues of the superhero. We are only interested in the dialogues of the superhero.\n",
    "- Removes the extra characters from the dialogues. We only keep the dialogues that have uppercase characters, spaces, and some special characters and that too till a maximum of 3 dialogues.\n",
    "- Combines the dialogues with the context of the previous dialogues. This is very essential for the model to learn the dialogues better. A dialogue without context is of no use. Dialogues when combined with the context of the previous dialogues can help the model understand the dialogues better.\n",
    "- Saves the dialogues with the context to a txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, based on these preprocessing steps, we have now successfully converted the movie scripts to dialogues with context only for the superheroes that we are interested in. This will help us in building a better chatbot. The quality of the data is very important for the model to give good results. Currently, each dialogue for a superhero that we created has 3 main things: Context, Dialogue, and extra characters dialogues. \n",
    "\n",
    "Ideally we would like to have only the context and the dialogue, removing the extra characters dialogues along with some screenplays that are present in the dialogues. For this, blog I have tried to keep it as it is; context, dialogue, and extra characters dialogues. But you can always modify the code to remove the extra characters dialogues and screenplays from the dialogues as well. Once other possible preprocessing step post-extraction is extract just the dialogues and context and remove the extra characters dialogues and screenplays from the dialogues using LLMs. This will help in improving the quality of the data. I have provided the code for the same in the code section below, but I have not used it in this blog since filtering the dialogues using LLMs is a time and resource-consuming process. But you can always use it to improve the quality of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import transformers\n",
    "\n",
    "\n",
    "# def load_model_pipeline(model_id, batch_size):\n",
    "#     '''\n",
    "#     Load the model pipeline with the model id and the batch size\n",
    "#     '''\n",
    "#     pipeline = transformers.pipeline(\n",
    "#         \"text-generation\",\n",
    "#         model=model_id,\n",
    "#         model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#         device_map=\"auto\",\n",
    "#         batch_size=batch_size,\n",
    "#     )\n",
    "\n",
    "#     torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "#     torch.backends.cuda.enable_flash_sdp(False)\n",
    "#     return pipeline\n",
    "\n",
    "# def extract_dialogue_from_llm(pipeline, messages):\n",
    "#     '''\n",
    "#     Extract the dialogues only from the model based on the messages\n",
    "#     '''\n",
    "#     pipeline.tokenizer.pad_token_id = pipeline.tokenizer.eos_token_id\n",
    "#     pipeline.tokenizer.padding_side = 'left'\n",
    "\n",
    "#     terminators = [\n",
    "#         pipeline.tokenizer.eos_token_id,\n",
    "#         pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "#     ]\n",
    "\n",
    "#     outputs = pipeline(\n",
    "#         messages,\n",
    "#         max_new_tokens=256,\n",
    "#         eos_token_id=terminators,\n",
    "#         do_sample=True,\n",
    "#         temperature=1,\n",
    "#         top_p=1,\n",
    "#     )\n",
    "\n",
    "#     return outputs\n",
    "\n",
    "# def create_batch(extrcated_split_script_text, superhero, superhero_names, batch_size):\n",
    "#     '''\n",
    "#     To make the extraction of the dialogues faster, we will create a batch of messages\n",
    "#     Messages are the prompts that has information about the system and the user\n",
    "#     '''\n",
    "#     messages_batch = []\n",
    "#     for extracted_text in tqdm(extrcated_split_script_text[:batch_size]):\n",
    "#         system_prompt = f\"You are a movie dialogue separator. From the context you are given, separate the dialogue and provide the dialogue of a charachter. You are only allowed to give final dialoige without any thing. Don't say anything else, just list the dialogue. Always start with the NAME of the character followed by a colon and then the dialogue. The extracted dialogue should always be in single line. Make sure that you extract all the dialouges of the asked charachters. It can be present in multiple lines. These are the identifier for charachter dialoges for which you need to extrcat the dialouges: {\", \".join([f\"'{i}'\" for i in superhero_names])} The identifier are always in captital leter.\"\n",
    "#         user_prompt = f\"Extract only the dialogues of {superhero.upper()} - Synonyms of {superhero.upper()} are {\", \".join([f\"'{i}'\" for i in superhero_names])}. Now extract dialogue based on the synonyms given from the following text\\n\\n\\n\\n {extracted_text} \\n\\n\\n\\n\\n Make sure you only extract dialogue of {\", \".join([f\"'{i}'\" for i in superhero_names])}. The dialogues starts only after the name of the charachter is in capital letter.\"\n",
    "\n",
    "#         messages = [\n",
    "#             {\"role\": \"system\", \"content\": system_prompt},\n",
    "#             {\"role\": \"user\", \"content\": user_prompt},\n",
    "#         ]\n",
    "#         messages_batch.append(messages)\n",
    "#     return messages_batch\n",
    "\n",
    "# batch_size = 8\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# pipeline = load_model_pipeline(model_id, batch_size)\n",
    "# messages_batch = create_batch(extrcated_split_script_text, superhero, superhero_names, batch_size)\n",
    "# extrcated_dialogue = extract_dialogue_from_llm(pipeline, messages_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, building a superhero character AI is a fascinating endeavor that merges technology with the beloved world of superheroes. By following the outlined approach, we can create an engaging platform where fans can interact with their favorite characters in an unprecedented way. This project not only showcases the potential of AI in entertainment and gaming but also highlights the creative possibilities that arise when technology intersects with popular culture. With the code committed to GitHub and a user-friendly interface ready for interaction, this superhero chat AI stands as a testament to the innovative capabilities of modern AI and its power to transform how we engage with fictional worlds.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Finally, we have successfully built a superhero character chatbot using the Haystack framework. We have also built a user interface for the chatbot using Streamlit. This chatbot can be used to interact with the superheroes and get responses from them. Though this started as a fun project, it has the potential to be expanded into a full-fledged chatbot that can engage with users on a variety of topics. Building a chatbot for superheroes character is a great way to engage with fans and provide them with a unique experience. The chatbot can be further improved by adding more superheroes and dialogues to the dataset. Overall, in this blog, we have seen how to build a superhero character chatbot using the Haystack framework and Streamlit. I hope you enjoyed reading this blog and learned something new. If you have any questions or feedback, feel free to leave a comment below. Thank you for reading!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
