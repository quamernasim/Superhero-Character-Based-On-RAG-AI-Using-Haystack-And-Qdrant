{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '..'\n",
    "data_folder = 'data'\n",
    "script_folder = 'scripts'\n",
    "dialogue_folder = 'dialogues'\n",
    "config_file = 'config.yaml'\n",
    "embed_dim = 384\n",
    "vector_store_name = 'QDRANT_VECTOR_DATABASE'\n",
    "vector_store_path = pjoin(root, vector_store_name)\n",
    "embedding_model = 'BAAI/bge-small-en-v1.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "superhero = 'Thanos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = pjoin(root, config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack_integrations.document_stores.qdrant import QdrantDocumentStore\n",
    "from haystack_integrations.components.retrievers.qdrant import QdrantEmbeddingRetriever\n",
    "from haystack.components.generators import HuggingFaceTGIGenerator\n",
    "from haystack_integrations.components.embedders.fastembed import FastembedTextEmbedder\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.components.others import Multiplexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_superhero_names(superhero, config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    superhero_synonym = config['SUPERHERO_SYNONYMS'][superhero][0]\n",
    "    superhero_names = [superhero.upper(), superhero_synonym.upper(), superhero_synonym.replace(' ', '-').upper()]\n",
    "    superhero_names = list(set(superhero_names))\n",
    "    return superhero_names\n",
    "\n",
    "def load_document_store(vector_store_path, superhero, embed_dim):\n",
    "    document_store = QdrantDocumentStore(\n",
    "        path=vector_store_path,\n",
    "        index=superhero,\n",
    "        embedding_dim=embed_dim,\n",
    "    )\n",
    "    return document_store\n",
    "\n",
    "def build_prompt():\n",
    "    prompt = \"\"\"\n",
    "    You are a helpful AI assistant that mimics the tone of the specified character based on provided context documents. Use the context to capture and replicate the character's tone accurately.\n",
    "\n",
    "    You will be given a set of CONTEXT documents, which you should use to understand and replicate the character's tone in your response. The context should primarily inform the tone rather than the content of your answer. You may answer questions without the context if it is not necessary, but always ensure your tone matches that of the character.\n",
    "\n",
    "    Respond without prefacing with phrases like \"Based on the context...\" or \"I think...\".\n",
    "\n",
    "    ******************************************\n",
    "    Context:\n",
    "    {% for document in documents %}\n",
    "    {{ document.content }}\n",
    "    ------------------------------------------\n",
    "    {% endfor %}\n",
    "    ******************************************\n",
    "    Copy the tone of these charachters : {{ superhero_names }} dialogue and answer the following question:\n",
    "    ******************************************\n",
    "    Question: {{ query }}\n",
    "    ******************************************\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the prompt builder\n",
    "    prompt_builder = PromptBuilder(template=prompt)\n",
    "    return prompt_builder\n",
    "\n",
    "def build_rag_pipeline(embedder, retriever, prompt_builder, generator):\n",
    "    rag = Pipeline()\n",
    "\n",
    "    rag.add_component(instance=Multiplexer(str), name=\"multiplexer\")\n",
    "\n",
    "    rag.add_component(\"embedder\", embedder)\n",
    "    rag.add_component(\"retriever\", retriever)\n",
    "    rag.add_component(\"prompt\", prompt_builder)\n",
    "    rag.add_component(\"llm\", generator)\n",
    "\n",
    "    rag.connect(\"multiplexer.value\", \"embedder.text\")\n",
    "    rag.connect(\"multiplexer.value\", \"prompt.query\")\n",
    "\n",
    "    rag.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "    rag.connect(\"retriever.documents\", \"prompt.documents\")\n",
    "    rag.connect(\"prompt.prompt\", \"llm\")\n",
    "\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = 'BAAI/bge-small-en-v1.5'\n",
    "llm_model = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "max_new_tokens = 250\n",
    "number_of_documents_to_retrieve = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "superhero_names = get_superhero_names(superhero, config_path)\n",
    "document_store = load_document_store(vector_store_path, superhero, embed_dim)\n",
    "prompt_builder = build_prompt()\n",
    "\n",
    "generator = HuggingFaceTGIGenerator(model=llm_model, generation_kwargs={\"max_new_tokens\": max_new_tokens})\n",
    "retriever = QdrantEmbeddingRetriever(document_store=document_store, top_k=number_of_documents_to_retrieve)\n",
    "embedder = FastembedTextEmbedder(model = embedding_model)\n",
    "\n",
    "rag = build_rag_pipeline(embedder, retriever, prompt_builder, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Who is thanos?'\n",
    "\n",
    "pipeline_input = {\n",
    "    \"multiplexer\": {\n",
    "        \"value\": question,\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"superhero_names\": superhero_names\n",
    "    }\n",
    "}\n",
    "\n",
    "result = rag.run(pipeline_input)\n",
    "response = result['llm']['replies'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag.show()\n",
    "# rag.draw(\"pipeline.png\")\n",
    "# print(rag.dumps())\n",
    "# pipe = Pipeline.loads(pipeline_yaml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
